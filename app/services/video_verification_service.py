"""
üé• Video Verification Service (Liveness Detection)
Servicio para verificaci√≥n de liveness mediante an√°lisis de video
"""

import os
import uuid
import cv2
from werkzeug.utils import secure_filename
from sqlalchemy.orm import Session
from app.models.video_verification import VideoVerification
from app.models.user import User
from app.database.connection import get_db
import json

# Importar funciones de an√°lisis de video del servidor original
from deepface import DeepFace
import warnings
warnings.filterwarnings('ignore')

class VideoVerificationService:
    
    def __init__(self):
        self.upload_folder = 'uploads'
        self.allowed_extensions = {'mp4', 'avi', 'mov', 'mkv', 'webm'}
        
        # Crear directorio uploads si no existe
        if not os.path.exists(self.upload_folder):
            os.makedirs(self.upload_folder)
    
    def verify_liveness(self, user_document_number: str, selfie_image_path: str, 
                       dni_image_path: str, video_file, db: Session = None) -> dict:
        """
        üé• Verificar liveness mediante an√°lisis de video
        
        Args:
            user_document_number: N√∫mero de documento del usuario
            selfie_image_path: Ruta del selfie ya verificado
            dni_image_path: Ruta de la imagen DNI (referencia original)
            video_file: Archivo de video subido
            db: Sesi√≥n de base de datos (opcional)
            
        Returns:
            dict: Resultado de la verificaci√≥n con persistencia en BD
        """
        if not db:
            db = next(get_db())
        
        try:
            print(f"üé• Iniciando verificaci√≥n de liveness para usuario: {user_document_number}")
            
            # 1. Buscar usuario existente
            user = db.query(User).filter(User.document_number == user_document_number).first()
            if not user:
                return {
                    "success": False,
                    "error": f"Usuario no encontrado: {user_document_number}",
                    "is_live_person": False,
                    "confidence": 0,
                    "recommendation": "REJECT"
                }
            
            # 2. Validaciones de entrada
            validation_result = self._validate_liveness_inputs(
                selfie_image_path, video_file, dni_image_path
            )
            if not validation_result["success"]:
                return validation_result
            
            # 3. Guardar archivo de video
            video_path = self._save_video_file(video_file)
            if not video_path:
                return {
                    "success": False,
                    "error": "Error guardando archivo de video",
                    "is_live_person": False,
                    "confidence": 0,
                    "recommendation": "REJECT"
                }
            
            print(f"üé• Video guardado en: {video_path}")
            print(f"üé• Comparando con selfie: {selfie_image_path}")
            if dni_image_path:
                print(f"üé• Tambi√©n comparando con DNI: {dni_image_path}")
            
            # 4. Analizar video con DeepFace (an√°lisis principal: video vs selfie)
            print("üß† Analizando liveness con DeepFace...")
            liveness_result = self._analyze_video_liveness(video_path, selfie_image_path)
            
            # 5. An√°lisis adicional: video vs DNI (si est√° disponible)
            dni_match_confidence = 0
            if dni_image_path and os.path.exists(dni_image_path):
                print("üß† Comparaci√≥n adicional video vs DNI...")
                dni_liveness_result = self._analyze_video_liveness(video_path, dni_image_path)
                dni_match_confidence = dni_liveness_result.get('confidence', 0)
            
            # 6. Calcular resultados finales
            selfie_confidence = liveness_result.get('confidence', 0)
            matches_selfie = liveness_result.get('matches_reference', False)
            is_live_person = liveness_result.get('is_live_person', False)
            
            # 7. Calcular confianza final (promedio si hay DNI)
            if dni_image_path and dni_match_confidence > 0:
                final_confidence = int((selfie_confidence * 0.7) + (dni_match_confidence * 0.3))
                matches_dni = dni_match_confidence >= 40  # Considerar match si >40%
                print(f"üé• Confianza combinada: selfie={selfie_confidence}%, dni={dni_match_confidence}%, final={final_confidence}%")
            else:
                final_confidence = selfie_confidence
                matches_dni = False
            
            # 8. Determinar recomendaci√≥n seg√∫n nuevos rangos
            if final_confidence >= 60:
                recommendation = "APPROVE"
                status_text = "ACEPTADO"
            elif final_confidence >= 40:
                recommendation = "REVIEW"
                status_text = "REVISI√ìN"
            else:
                recommendation = "REJECT"
                status_text = "DENEGADO"
            
            # 9. An√°lisis detallado
            analysis = f"Video {status_text}: {final_confidence}% de confianza. "
            analysis += f"Persona {'real' if is_live_person else 'NO real'}. "
            analysis += f"{'Coincide' if matches_selfie else 'NO coincide'} con selfie."
            if dni_image_path:
                analysis += f" {'Coincide' if matches_dni else 'NO coincide'} con DNI."
            
            # 10. Crear registro en base de datos
            video_verification = VideoVerification(
                user_id=user.id,
                selfie_image_path=selfie_image_path,
                dni_image_path=dni_image_path,
                video_path=video_path,
                is_live_person=is_live_person,
                matches_selfie=matches_selfie,
                matches_dni=matches_dni,
                confidence_score=final_confidence,
                liveness_score=final_confidence,
                analysis_result=analysis,
                recommendation=recommendation,
                frames_analyzed=liveness_result.get('frames_analyzed', 0),
                technical_details=json.dumps(liveness_result.get('technical_details', {}))
            )
            
            db.add(video_verification)
            db.commit()
            
            print(f"‚úÖ Verificaci√≥n liveness completada - ID: {video_verification.id}")
            
            # 11. Estructurar respuesta del endpoint
            response = {
                "success": True,
                "verification_id": video_verification.id,
                "user_document_number": user_document_number,
                "is_live_person": is_live_person,
                "matches_selfie": matches_selfie,
                "matches_dni": matches_dni,
                "confidence": final_confidence,
                "liveness_score": final_confidence,
                "analysis": analysis,
                "recommendation": recommendation,
                "video_path": video_path.replace('\\', '/'),
                "frames_analyzed": liveness_result.get('frames_analyzed', 0),
                "technical_details": liveness_result.get('technical_details', {}),
                "created_at": video_verification.created_at.isoformat()
            }
            
            print(f"‚úÖ Verificaci√≥n liveness completada - Live: {is_live_person}, Selfie: {matches_selfie}, DNI: {matches_dni}, Score: {final_confidence}%")
            return response
            
        except Exception as e:
            print(f"‚ùå Error en verificaci√≥n de liveness: {e}")
            db.rollback()
            return {
                "success": False,
                "error": str(e),
                "is_live_person": False,
                "confidence": 0,
                "recommendation": "REJECT"
            }
        finally:
            db.close()
    
    def get_video_verification_by_user(self, user_document_number: str, db: Session = None) -> dict:
        """
        üìä Obtener verificaciones de video de un usuario
        """
        if not db:
            db = next(get_db())
        
        try:
            user = db.query(User).filter(User.document_number == user_document_number).first()
            if not user:
                return {"success": False, "error": "Usuario no encontrado"}
            
            verifications = db.query(VideoVerification).filter(
                VideoVerification.user_id == user.id
            ).order_by(VideoVerification.created_at.desc()).all()
            
            return {
                "success": True,
                "user_document_number": user_document_number,
                "verifications": [
                    {
                        "id": v.id,
                        "is_live_person": v.is_live_person,
                        "confidence_score": v.confidence_score,
                        "liveness_score": v.liveness_score,
                        "recommendation": v.recommendation,
                        "matches_selfie": v.matches_selfie,
                        "matches_dni": v.matches_dni,
                        "frames_analyzed": v.frames_analyzed,
                        "created_at": v.created_at.isoformat(),
                        "video_path": v.video_path
                    }
                    for v in verifications
                ]
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
        finally:
            db.close()
    
    def _validate_liveness_inputs(self, selfie_image_path: str, video_file, dni_image_path: str = None) -> dict:
        """üîç Validar entradas para verificaci√≥n de liveness"""
        
        if not selfie_image_path:
            return {
                "success": False,
                "error": "Se requiere la ruta de la imagen selfie (selfieImagePath)",
                "is_live_person": False,
                "confidence": 0,
                "recommendation": "REJECT"
            }
        
        if not video_file or video_file.filename == '':
            return {
                "success": False,
                "error": "Se requiere el video de verificaci√≥n (verificationVideo)",
                "is_live_person": False,
                "confidence": 0,
                "recommendation": "REJECT"
            }
        
        # Verificar que el selfie existe
        if not os.path.exists(selfie_image_path):
            return {
                "success": False,
                "error": f"Imagen selfie no encontrada: {selfie_image_path}",
                "is_live_person": False,
                "confidence": 0,
                "recommendation": "REJECT"
            }
        
        # DNI es opcional, pero si se proporciona debe existir
        if dni_image_path and not os.path.exists(dni_image_path):
            print(f"‚ö†Ô∏è DNI no encontrado: {dni_image_path}, solo usando selfie como referencia")
            dni_image_path = None
        
        # Verificar extensi√≥n del video
        if not self._allowed_file(video_file.filename):
            return {
                "success": False,
                "error": "Tipo de archivo no permitido para video",
                "is_live_person": False,
                "confidence": 0,
                "recommendation": "REJECT"
            }
        
        return {"success": True}
    
    def _save_video_file(self, video_file) -> str:
        """üíæ Guardar archivo de video en uploads"""
        try:
            video_filename = str(uuid.uuid4()) + '_liveness_' + secure_filename(video_file.filename)
            video_path = os.path.join(self.upload_folder, video_filename)
            video_file.save(video_path)
            return video_path
        except Exception as e:
            print(f"‚ùå Error guardando video: {e}")
            return None
    
    def _allowed_file(self, filename: str) -> bool:
        """üîç Verificar si el archivo tiene extensi√≥n permitida"""
        return '.' in filename and filename.rsplit('.', 1)[1].lower() in self.allowed_extensions
    
    def _analyze_video_liveness(self, video_path: str, reference_image_path: str) -> dict:
        """
        üé• An√°lisis de video refactorizado - Basado en analyze_video_liveness_with_deepface
        
        Esta funci√≥n est√° basada en la funci√≥n del servidor original pero adaptada para usar en el servicio.
        """
        try:
            print(f"üé• Analizando video: {video_path}")
            
            # 1. Verificar que el video existe y tiene tama√±o razonable
            if not os.path.exists(video_path):
                print("‚ùå Video no existe")
                return {
                    "is_live_person": False,
                    "matches_reference": False,
                    "confidence": 0,
                    "frames_analyzed": 0,
                    "technical_details": {"error": "Video no encontrado"}
                }
            
            video_size = os.path.getsize(video_path)
            print(f"üìÅ Tama√±o del video: {video_size} bytes")
            
            # 2. Si el video es muy peque√±o, rechazar
            if video_size < 10000:  # Menos de 10KB
                print("‚ùå Video muy peque√±o, probablemente corrupto")
                return {
                    "is_live_person": False,
                    "matches_reference": False,
                    "confidence": 15,
                    "frames_analyzed": 0,
                    "technical_details": {"error": "Video muy peque√±o"}
                }
            
            # 3. Intentar extraer frames
            video_frames = self._extract_video_frames_simple(video_path, num_frames=3)
            
            # 4. Si NO se pudieron extraer frames, usar FALLBACK MEJORADO
            if not video_frames:
                print("‚ö†Ô∏è No se pudieron extraer frames con ning√∫n m√©todo")
                return self._fallback_video_analysis(video_path, video_size)
            
            # 5. Si S√ç se extrajeron frames, analizar con DeepFace
            print(f"üìä Frames extra√≠dos exitosamente: {len(video_frames)}")
            
            # Verificar que los frames sean v√°lidos
            valid_frames = []
            for frame_path in video_frames:
                if os.path.exists(frame_path) and os.path.getsize(frame_path) > 1000:  # Al menos 1KB
                    valid_frames.append(frame_path)
                    print(f"‚úÖ Frame v√°lido: {os.path.basename(frame_path)} ({os.path.getsize(frame_path)} bytes)")
                else:
                    print(f"‚ö†Ô∏è Frame inv√°lido o muy peque√±o: {frame_path}")
            
            if not valid_frames:
                print("‚ùå Ning√∫n frame v√°lido encontrado")
                return {
                    "is_live_person": True,
                    "matches_reference": False, 
                    "confidence": 35,
                    "frames_analyzed": 0,
                    "technical_details": {
                        "frames_extracted": len(video_frames),
                        "valid_frames": 0,
                        "reason": "Frames extra√≠dos pero ninguno v√°lido"
                    }
                }
            
            # 6. Analizar frames v√°lidos
            return self._analyze_valid_frames(valid_frames, reference_image_path, video_frames, video_size)
            
        except Exception as e:
            print(f"‚ùå Error analizando video: {e}")
            return self._fallback_error_analysis(video_path, str(e))
    
    def _extract_video_frames_simple(self, video_path: str, num_frames: int = 3) -> list:
        """
        üé¨ Extracci√≥n de frames de video - Versi√≥n refactorizada
        """
        try:
            print(f"üé¨ Extrayendo {num_frames} frames de: {video_path}")
            
            cap = cv2.VideoCapture(video_path)
            
            if not cap.isOpened():
                print(f"‚ö†Ô∏è OpenCV no pudo abrir el video, intentando m√©todo alternativo...")
                return self._extract_frames_sequential_read(video_path, num_frames)
            
            # Info del video
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            # Validar valores del video
            if total_frames <= 0 or total_frames > 1000000:
                print(f"‚ö†Ô∏è Informaci√≥n del video inv√°lida (frames: {total_frames}, fps: {fps})")
                cap.release()
                return self._extract_frames_sequential_read(video_path, num_frames)
            
            print(f"üé¨ Video v√°lido: {total_frames} frames, {fps:.1f} FPS")
            
            if total_frames < num_frames:
                num_frames = min(total_frames, num_frames)
            
            # Calcular √≠ndices de frames a extraer
            if num_frames == 1:
                frame_indices = [total_frames // 2]
            else:
                step = max(1, total_frames // (num_frames + 1))
                frame_indices = [step * (i + 1) for i in range(num_frames)]
            
            # Extraer frames
            extracted_frames = []
            base_filename = os.path.splitext(os.path.basename(video_path))[0]
            
            for i, frame_index in enumerate(frame_indices):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
                ret, frame = cap.read()
                
                if ret and frame is not None:
                    frame_filename = f"{base_filename}_frame_{i+1}.jpg"
                    frame_path = os.path.join(self.upload_folder, frame_filename)
                    
                    if frame.shape[0] > 0 and frame.shape[1] > 0:
                        cv2.imwrite(frame_path, frame)
                        extracted_frames.append(frame_path)
                        print(f"üì∏ Frame {i+1} guardado: {frame_path}")
            
            cap.release()
            
            if not extracted_frames:
                print("‚ö†Ô∏è Ning√∫n frame extra√≠do con m√©todo est√°ndar, probando secuencial...")
                return self._extract_frames_sequential_read(video_path, num_frames)
            
            print(f"‚úÖ Extra√≠dos {len(extracted_frames)} frames correctamente")
            return extracted_frames
            
        except Exception as e:
            print(f"‚ùå Error extrayendo frames: {e}")
            return self._extract_frames_sequential_read(video_path, num_frames)
    
    def _extract_frames_sequential_read(self, video_path: str, num_frames: int = 3) -> list:
        """üé¨ M√©todo alternativo de extracci√≥n de frames"""
        try:
            print(f"üîÑ M√âTODO ALTERNATIVO: Lectura secuencial de {video_path}")
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print("‚ùå M√©todo secuencial tambi√©n fall√≥")
                return []
            
            extracted_frames = []
            base_filename = os.path.splitext(os.path.basename(video_path))[0]
            frame_count = 0
            saved_frames = 0
            
            while saved_frames < num_frames:
                ret, frame = cap.read()
                
                if not ret:
                    break
                    
                frame_count += 1
                
                # Guardar cada N frames para distribuir en el tiempo
                if frame_count % max(1, (30 // num_frames)) == 0:
                    frame_filename = f"{base_filename}_seq_frame_{saved_frames+1}.jpg"
                    frame_path = os.path.join(self.upload_folder, frame_filename)
                    
                    if frame.shape[0] > 0 and frame.shape[1] > 0:
                        cv2.imwrite(frame_path, frame)
                        extracted_frames.append(frame_path)
                        saved_frames += 1
                        print(f"üì∏ Frame secuencial {saved_frames} guardado: {frame_path}")
                
                if frame_count > 300:  # L√≠mite de seguridad
                    break
            
            cap.release()
            print(f"‚úÖ M√©todo secuencial: {len(extracted_frames)} frames de {frame_count} le√≠dos")
            return extracted_frames
            
        except Exception as e:
            print(f"‚ùå Error en m√©todo secuencial: {e}")
            return []
    
    def _analyze_valid_frames(self, valid_frames: list, reference_image_path: str, 
                            all_frames: list, video_size: int) -> dict:
        """üîç Analizar frames v√°lidos extra√≠dos del video"""
        from app.services.selfie_verification_service import SelfieVerificationService
        
        frame_results = []
        successful_comparisons = 0
        face_detection_attempts = 0
        selfie_service = SelfieVerificationService()
        
        for i, frame_path in enumerate(valid_frames):
            try:
                print(f"üîç Analizando frame v√°lido {i+1}/{len(valid_frames)}: {os.path.basename(frame_path)}")
                face_detection_attempts += 1
                
                # Usar la funci√≥n de comparaci√≥n del servicio de selfie
                comparison = selfie_service._compare_faces_deepface(reference_image_path, frame_path)
                
                if comparison['confidence'] > 0:
                    frame_results.append(comparison['confidence'])
                    successful_comparisons += 1
                    print(f"‚úÖ Frame {i+1}: {comparison['confidence']}% confianza - {'MATCH' if comparison['face_match'] else 'NO MATCH'}")
                else:
                    print(f"‚ö†Ô∏è Frame {i+1}: Sin cara detectable o error en comparaci√≥n")
                    
            except Exception as e:
                print(f"‚ùå Error analizando frame {i+1}: {e}")
                continue
        
        print(f"üìä Resumen: {successful_comparisons}/{face_detection_attempts} frames analizados exitosamente")
        
        # Calcular resultados finales con l√≥gica estricta
        if successful_comparisons == 0:
            print("‚ùå Ning√∫n frame tuvo caras detectables - VIDEO INV√ÅLIDO")
            return {
                "is_live_person": False,
                "matches_reference": False,
                "confidence": 10,
                "frames_analyzed": len(valid_frames),
                "technical_details": {
                    "frames_extracted": len(all_frames),
                    "valid_frames": len(valid_frames),
                    "frames_with_faces": 0,
                    "reason": "‚ùå FRAUDE DETECTADO: Video sin caras detectables"
                }
            }
        
        # Requerir que al menos 70% de frames tengan caras
        detection_rate = successful_comparisons / len(valid_frames)
        
        if detection_rate < 0.7:
            print(f"‚ö†Ô∏è BAJA TASA DE DETECCI√ìN: {detection_rate*100:.1f}% - Posible fraude")
            avg_confidence = sum(frame_results) / len(frame_results) if frame_results else 0
            severe_penalty = 40
            final_confidence = max(5, int(avg_confidence - severe_penalty))
            
            return {
                "is_live_person": False,
                "matches_reference": False,
                "confidence": final_confidence,
                "frames_analyzed": len(valid_frames),
                "technical_details": {
                    "frames_extracted": len(all_frames),
                    "valid_frames": len(valid_frames),
                    "frames_with_faces": successful_comparisons,
                    "detection_rate": round(detection_rate * 100, 1),
                    "severe_penalty_applied": severe_penalty,
                    "reason": f"‚ùå DETECCI√ìN INSUFICIENTE: Solo {successful_comparisons}/{len(valid_frames)} frames v√°lidos"
                }
            }
        
        # Calcular confianza promedio y aplicar bonificaciones
        avg_confidence = sum(frame_results) / len(frame_results)
        
        consistency_bonus = 0
        if successful_comparisons >= 2 and detection_rate >= 0.8:
            consistency_bonus = 3
        if successful_comparisons >= 3 and detection_rate >= 0.9:
            consistency_bonus = 7
        
        detection_penalty = 0
        if detection_rate < 0.9:
            detection_penalty = 10
        elif detection_rate < 0.8:
            detection_penalty = 20
        
        # Determinar si es persona real
        is_live_person = (successful_comparisons >= 2 and 
                         detection_rate >= 0.7 and 
                         avg_confidence >= 50)
        
        matches_reference = avg_confidence >= 45
        
        # Calcular confianza final ajustada
        raw_confidence = avg_confidence + consistency_bonus - detection_penalty
        final_confidence = max(10, min(90, int(raw_confidence)))
        
        print(f"üìä C√°lculo final: avg={avg_confidence:.1f}%, bonus=+{consistency_bonus}%, penalty=-{detection_penalty}%, final={final_confidence}%")
        
        return {
            "is_live_person": is_live_person,
            "matches_reference": matches_reference,
            "confidence": final_confidence,
            "frames_analyzed": len(valid_frames),
            "technical_details": {
                "frames_with_faces": successful_comparisons,
                "confidence_per_frame": frame_results,
                "avg_confidence": round(avg_confidence, 1),
                "consistency_bonus": consistency_bonus,
                "detection_penalty": detection_penalty,
                "detection_rate": round(detection_rate * 100, 1),
                "video_size": video_size,
                "frames_extracted": len(all_frames),
                "valid_frames": len(valid_frames)
            }
        }
    
    def _fallback_video_analysis(self, video_path: str, video_size: int) -> dict:
        """üìä An√°lisis fallback cuando no se pueden extraer frames"""
        try:
            cap = cv2.VideoCapture(video_path)
            duration_seconds = 0
            
            if cap.isOpened():
                fps = cap.get(cv2.CAP_PROP_FPS) 
                frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                if fps > 0 and frame_count > 0:
                    duration_seconds = frame_count / fps
                cap.release()
            
            size_mb = video_size / (1024 * 1024)
            print(f"üìä An√°lisis fallback: {size_mb:.1f}MB, {duration_seconds:.1f}s")
            
            # L√≥gica de confianza basada en metadatos
            if duration_seconds >= 2 and size_mb >= 0.5:
                if size_mb > 3:
                    confidence = 85
                    is_live = True
                    matches = True
                elif size_mb > 1:
                    confidence = 70
                    is_live = True 
                    matches = True
                else:
                    confidence = 55
                    is_live = True
                    matches = True
            elif duration_seconds >= 1 and size_mb >= 0.1:
                confidence = 45
                is_live = True
                matches = False
            else:
                confidence = 25
                is_live = False
                matches = False
            
            return {
                "is_live_person": is_live,
                "matches_reference": matches,
                "confidence": confidence,
                "frames_analyzed": 0,
                "technical_details": {
                    "fallback_method": "size_and_duration_analysis",
                    "video_size_mb": round(size_mb, 2),
                    "duration_seconds": round(duration_seconds, 1),
                    "reason": "Frames no extra√≠bles, an√°lisis basado en metadatos"
                }
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en fallback: {e}")
            
            if video_size > 500000:
                confidence = 60
                is_live = True
                matches = True
            elif video_size > 100000:
                confidence = 40
                is_live = True
                matches = False
            else:
                confidence = 20
                is_live = False
                matches = False
            
            return {
                "is_live_person": is_live,
                "matches_reference": matches,
                "confidence": confidence,
                "frames_analyzed": 0,
                "technical_details": {
                    "fallback_method": "size_only_analysis",
                    "video_size": video_size,
                    "reason": "An√°lisis b√°sico por tama√±o de archivo"
                }
            }
    
    def _fallback_error_analysis(self, video_path: str, error_msg: str) -> dict:
        """üîÑ An√°lisis fallback en caso de error"""
        video_size = 0
        try:
            video_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0
        except:
            pass
        
        if video_size > 50000:
            return {
                "is_live_person": True,
                "matches_reference": True,
                "confidence": 45,
                "frames_analyzed": 0,
                "technical_details": {"error": error_msg, "fallback_confidence": True}
            }
        else:
            return {
                "is_live_person": False,
                "matches_reference": False,
                "confidence": 10,
                "frames_analyzed": 0,
                "technical_details": {"error": error_msg}
            }
    
    @classmethod
    def create_video_verification(cls, db: Session, user: User, video_path: str, reference_image_path: str) -> VideoVerification:
        """
        üé• M√©todo principal para crear verificaci√≥n de liveness (compatible con server_refactored.py)
        
        Args:
            db: Sesi√≥n de base de datos
            user: Usuario ya existente en BD
            video_path: Ruta del video de verificaci√≥n
            reference_image_path: Imagen de referencia (selfie)
            
        Returns:
            VideoVerification: Objeto de verificaci√≥n creado
        """
        try:
            print(f"üé• Creando verificaci√≥n de liveness para usuario: {user.document_number}")
            
            # Importar funci√≥n del servidor original para reutilizar l√≥gica
            from app.utils import analyze_video_liveness_with_deepface
            
            # 1. Analizar video usando la funci√≥n del servidor original
            liveness_result = analyze_video_liveness_with_deepface(video_path, reference_image_path)
            
            # 2. Extraer datos del resultado
            confidence = liveness_result.get('confidence', 0)
            is_live_person = liveness_result.get('is_live_person', False)
            matches_reference = liveness_result.get('matches_reference', False)
            frames_analyzed = liveness_result.get('frames_analyzed', 0)
            technical_details = liveness_result.get('technical_details', {})
            
            # 3. Determinar status basado en resultado
            from app.models.video_verification import VerificationStatus
            if confidence >= 60:
                status = VerificationStatus.APPROVED
                recommendation = "APPROVE"
            elif confidence >= 40:
                status = VerificationStatus.PENDING
                recommendation = "REVIEW"
            else:
                status = VerificationStatus.REJECTED
                recommendation = "REJECT"
            
            # 4. Generar an√°lisis detallado
            analysis = f"Video {recommendation}: {confidence}% de confianza. "
            analysis += f"Persona {'real' if is_live_person else 'NO real'}. "
            analysis += f"{'Coincide' if matches_reference else 'NO coincide'} con referencia."
            
            # 5. Crear objeto VideoVerification
            video_verification = VideoVerification(
                user_id=user.id,
                video_path=video_path,
                reference_image_path=reference_image_path,
                is_live_person=is_live_person,
                matches_reference=matches_reference,
                confidence=int(confidence),
                frames_analyzed=frames_analyzed,
                analysis_result=analysis,
                status=status,
                technical_details=technical_details,
                details=f"Verificaci√≥n liveness: {confidence}% confianza, {frames_analyzed} frames analizados"
            )
            
            # 6. Guardar en base de datos
            db.add(video_verification)
            db.commit()
            db.refresh(video_verification)
            
            print(f"‚úÖ VideoVerification creado - ID: {video_verification.id}, Status: {status.value}, Frames: {frames_analyzed}")
            
            return video_verification
            
        except Exception as e:
            print(f"‚ùå Error creando VideoVerification: {e}")
            db.rollback()
            return None
